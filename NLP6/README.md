## Лабораторна робота №6 - LLM + RAG question answering
### Рівень - Рекомендований, Rag question  answering
---
##### Робота виконана студентами групи КН-417 - Френіс Володимир, Орлянський Максим



---
### Зміст README 
1.  Summary 
2. Опис обраної тематики для кої розроблялась RAG система
3. Використані набори даних, джерела
4. Опрацювання даних:
	4.1 Завантаження даних
	4.2 Попередня обробка та підготовка даних
	4.3 Chunking даних
5. LLM
	5.1 Обраний метод застосування моделі
	5.2 Обрана модель
	5.3 API ключ для доступу до моделі
6. Embeddings
	6.1 Підготовка до роботи з ембедингами
	6.2 Векторна база даних
7. Retriever
	7.1 BM25 пошук
	7.2 Dense пошук
	7.3 Full пошук (BM25 + Dense)
8. Reranker модель
9. Цитування(Citations)
10. UI
---

## **Задача**  
Розробка Retrieval-Augmented Generation (RAG) системи для роботи з PDF-документами, пов’язаними з науковими статтями на тему візуальної одометрії.

---

## **Опис компонентів**  

- **Data source**  
  PDF-документи (15 штук) зі статтями з наукових журналів. Перед обробкою PDF-документів застосовано лематизацію, щоб звести слова до їх базових форм

- **Chunking**  
  Використано метод RecursiveCharacterTextSplitter з LangChain для розбиття тексту на частини по 2048 символів із перекриттям у 200 символів.  

- **LLM**  
  Використано модель **groq/llama-8b-8192**.  

- **Retriever**  
  Розроблено три методи:  
  1. **BM25** — повертає 3 релевантні документи.  
  2. **Semantic** (на основі **intfloat/e5-large-v2**) — повертає 40 найбільш релевантних документів.  
  3. **FULL search** — комбінує BM25, Semantic + Reranker. Після об’єднання 6 документів (3 від BM25, 3 від Semantic + Reranker), Reranker обирає 3 з них.  

- **Reranker**  
  Використано модель **BAAI/bge-reranker-large**.  

- **Citations**  
  Система повертає назву документа та номер чанка, з якого отримано інформацію.  

- **UI**  
  Інтерфейс реалізовано за допомогою **Gradio**.  

- **Other**  
  **Metadata filtering**: N/A  

---

## **Учасники проєкту**  
- **Максим Орлянський**: Відповідальний за інтеграцію extracting data from pdf, LLM, Hybrid-Full retriever, UI.  
- **Френіс Володимир**: Відповідальний за Sparse BM25, Dense retriever, Reranker, Citations.  

---

## **Посилання на запущений сервіс**  
Сервіс запущений на платформі, де доступний GPU. Без GPU очікування відповідей для Semantic або Full може бути тривалим.  
Для прикладу, сервіс можна запустити на платформі Google Colab: [Посилання на ноутбук](#). 
Для першого запуску, враховуючи встановлення залежностей, потрібно до 10 хвилин. 



---
#### 1. Опис обраної тематики для кої розроблялась RAG система

У даній роботі ми розробили RAG систему для діставання релевантної інформації з текстів наукових статей присвячених темі візуальної одометрії для роботів.

---
#### 2. Використані набори даних, джерела
У даній роботі в якості основного датасету використовувалися 15 PDF файлів з науковими статтями з різних ресурсів таких як Springer, IEEE, arxiv.org та ін. 

Загалом сам датасет містить всі статті так чи інакше дотичні до тематики візуальної одометрії, де наведені різні алгоритми та експерименти із ними та результати.

Окрім датасету представленого у вигляді 15 PDF файлів є також варіант із завантаженими статтями у форматі CSV таблиці "odometry_data.csv", де присутні 3 стовпці *name*, *text*, *chunks* , де відповідно:
- *name* - назва PDF файлу із науковою статей
- *text*  - повний текст статті
- *chunks* - попередньо оброблені та підготовлені і розділенні шматочки тексту

---
#### 3. Завантаження даних
У вихідному коді проекту, для завантаження датасету чи то з PDF чи то з CSV імплементований клас **DataPdf**, який приймає на вхід шлях до датасету та завантажує його.

#### 3.1 Попередня обробка та підготовка даних
Після завантаження даних з ними проводиться процес їх підготовки до розділення на чанки та подальшого створення ембедінгів на основі чанків.

Так у випадку, якщо ми працює із PDF файлами, то першим кроком після зчитування тексту на англійській мові буде його лемантизація для усіх частин мови та переведення в lower-case. Процес лемантизації відбувається ха допомогою nltk wordnet. 

Говорячи про обробку CSV замість PDF файлів, то для датасету відбувається процес завантаження усіх наперед підготовлених чанків, та присвоєння кожному з них відповідного числового індексу.

#### 3.2 Chunking даних
Чанкінг даних відбувається лише за умови, якщо ми працюємо із PDF датасетом, так після препроцесінгу ми отримуємо чистий текст готовий до розбиття на чанки, які беруться за допомогою фунції RecursiveCharacterTextSplitter із розмірністю chunk_size=2048 символів на чанк, та параметр chunk_overlap обирається рівний ~10% від загального розміру чанку, що складає 200 символів. 

В якості основних розділювачів(separators), на які орієтується RecursiveCharacterTextSplitter виступають абзаци, переноси стрічок, та пробіли ["\n\n", "\n", " "] .

Відповідно за результатами роботи розбиття датасету на чанки ми отримуємо для PDF файлів готові до перетворення у вектори-ембедінги чанки, які можна буде використати в подальшому для RAG системи.

---

#### 4.1 Обраний метод застосування моделі
В даній роботі була обрана опція №1 доступу до готової LLM моделі через API доступу, до стороннього сервісу.

Таким сервісом в даному випадку виступив GROQ.

#### 4.2 Обрана модель
На сервісі GROQ в якості основної, була обрана модель *groq/llama3-8b-8192*, що є безплатною моделлю, і до якої можна доступитися по API ключу.

#### 4.3 API ключ для доступу до моделі
Якщо у рецинзента лабораторної роботи не має API ключа для даної моделі, він може скористатися цим ключем під час тестування кінцевого сервісу

***API_KEY*** 
```
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
```
---

#### 5.1 Підготовка до роботи з ембедингами
В даній роботі в якості моделі для генерації векторів ембедінгів для Dense та Full пошуку використовувалась модель SentenceTransformer:

> intfloat/e5-large-v2

Дана модель приймає на вхід отримані в результаті роботи чанкування і препроцесінгу даних з попереднього етапу та перетворює їх у вектори, обробляючи батчами по 32, та зберігає отримані вектори-ембедінги у векторну базу даних.

#### 5.2   Векторна база даних
В якості векторної бази даних у даній роботі була обрана FAISS база, через її популярність та можливість реалізації різних видів пошуку у ній. 

Так після завершення конвертування усіх чанків датасету  у вектори, векторна база даних FAISS зберігається у файл:
> faiss_index_e5_large.idx

Який в подальшому за потреби можна перевикористати для тих самих документів. 
Відповідно на прикінці цього етапу, уже є повінстю підготовлено усі дані для процесу діставання найбільш релевантних документів по запиту користувача, як для BM25 так і для Dense та Full пошуку.

---
#### 6 Retriver
Аби діставати найбільш релевантні записи, документи, які будуть допомагати LLM моделі відповідати на запитання користувача і давати їй конткест, потрібно обрати правельний спосіб діставання цих документів, для цього власне і використаємо Retriver. В даній роботі потрібно було реалізувати їх 3 версії, а саме:
- BM25 як пошук по ключових словах
- Dense search безпосередній семантичний пошук по відстанях запиту користувача і даних з векторів із векторної бази даних із пошуком найменш віддалених
- Загальний або ж Full search як гібрид попередніх двох.

Відповідно в підпунктах нижче наведено як саме, і що саме використовувалося для цього для кожного з Retriver-рів.

Для усіх трьох Retriver-рів було створено спільний клас TextRetriever, де кожен метод відповідає за конкретний підхід.

#### 6.1 BM25 пошук
Для реалізації BM25 використано готову функцію rank_bm25 із бібліотеки BM25Okapi, що дозволяє на основі TF-IDF визначити по ключових словах найбільш редевантні чанки для даного запиту.

Окрім цього для результатів використано також додатково Reranker, після чого метод повертає top_k=3 найбільш релевантні чанки-документи. 

#### 6.2 Dense пошук
Для реалізації Dense пошуку, було обрано ту саму модель ретрівера, що і використовувалась для створення ембедінгів:
> intfloat/e5-large-v2

В якості відстані на основі якої відбувався пошук k=40 найбільш релевантних документів у FAISS індексі, за вектором запиту користувача, було обрано косинусну відстань.

Відповідно як і для BM25 для Dense пошуку застосовується Reranking результатів після чого повертається top_k=3 результатів.

#### 6.3 Full пошук (BM25 + Dense)
В даній роботі в якості повного пошуку був використаний гібрид поєднання результатів роботи BM25 та Dense пошуків разом, та додаткове застосування над отриманими результатами Reranker-ру, в результаті чого, пошук повертає top_k=3 найбільш релевантних чанки, документи серед результатів BM25 та Dense пошуку.

---

#### 7.  Reranker
В даній роботі в якості Reranker-ру було обрано модель:
> BAAI/bge-reranker-large

Відповідно дана модель отримує на вхід результати згаданих раніше Retriver-рів, та повертає найбільш релевантні документи після перерахунку результатів та відстаней.

---

#### 8. Цитування(Citations)
В даній роботі реалізовано цитування, де на веб інтерфейсі після генерації відповіді моделі, виводяться назви PDF файлів з яких була взята інформація та номер чанку з виведеного PDF файлу. 

---

#### 9. UI
В даній роботі для реалізації UI веб інтерфейсу для доступу до моделі та її елементів і виводу, було обрано та застосовано бібліотеку Gradio

На сам веб інтерфейс було додано можливвість вводу апі ключа для доступу до моделі, можливість вводу запиту, вибір типу Retriver-ра для контексту, та можливість активації та деактивації Reranker-ра результатів, а також вивід результатів генерації та цитування.
